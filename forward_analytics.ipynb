{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:32:08.701903Z",
     "start_time": "2024-11-07T09:32:07.650407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import time"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load XML",
   "id": "20b9111729a7237d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:36:39.182972Z",
     "start_time": "2024-11-07T09:36:39.174693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xml_file_path = 'C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/20241031-gleif-concatenated-file-lei2.xml'\n",
    "out_path = \"C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/out\""
   ],
   "id": "3f74b3a7b063122a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:39:47.490624Z",
     "start_time": "2024-11-07T09:36:39.891708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "namespace = {'lei': 'http://www.gleif.org/data/schema/leidata/2016'}\n",
    "\n",
    "# Initialize a list to store the extracted data\n",
    "data = []\n",
    "\n",
    "try:  # Placeholder namespace, adjust if necessary\n",
    "\n",
    "    # Use iterparse to read the XML file\n",
    "\n",
    "    context = etree.iterparse(xml_file_path, events=('end',),\n",
    "                                  tag='{http://www.gleif.org/data/schema/leidata/2016}LEIRecord')\n",
    "\n",
    "    for event, lei_record in context:\n",
    "        lei = lei_record.find('.//lei:LEI', namespaces=namespace).text\n",
    "        legal_name = lei_record.find('.//lei:LegalName', namespaces=namespace).text\n",
    "        legal_form_code = lei_record.find('.//lei:EntityLegalFormCode', namespaces=namespace)\n",
    "        other_legal_form = lei_record.find('.//lei:OtherLegalForm', namespaces=namespace)\n",
    "\n",
    "        # Use fallback values for legal form fields\n",
    "        legal_form_code_text = legal_form_code.text if legal_form_code is not None else \"N/A\"\n",
    "        other_legal_form_text = other_legal_form.text if other_legal_form is not None else \"N/A\"\n",
    "\n",
    "        data.append({\n",
    "            'Entity_Name': legal_name,\n",
    "            'LEI': lei,\n",
    "            'Legal_Code': legal_form_code_text,\n",
    "            'Legal_Form': other_legal_form_text\n",
    "        })\n",
    "\n",
    "        # Clear the element to free memory\n",
    "        lei_record.clear()\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file '{xml_file_path}' was not found.\")\n",
    "except etree.XMLSyntaxError:\n",
    "    print(\"There was an error parsing the XML data.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "id": "4f973166cd290038",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Merge with Legal Form",
   "id": "3013ae75997c3819"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:40:32.304034Z",
     "start_time": "2024-11-07T09:40:32.271986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name_df = pd.read_csv(\"C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/2023-09-28-elf-code-list-v1.5.csv\")\n",
    "#rename for readability\n",
    "name_df = name_df[[\"Entity Legal Form name Transliterated name (per ISO 01-140-10)\", \"ELF Code\"]]\n",
    "name_df.rename(columns={\"Entity Legal Form name Transliterated name (per ISO 01-140-10)\": 'Legal_Form', 'ELF Code': 'Legal_Code'}, inplace=True)"
   ],
   "id": "3eea89889a3619cc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:40:58.104293Z",
     "start_time": "2024-11-07T09:40:56.070335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.merge(name_df, on=\"Legal_Code\", how=\"inner\", suffixes=('', '_drop'))\n",
    "df = df.loc[:, ~df.columns.str.endswith('_drop')]"
   ],
   "id": "c7a8cd23a9c5657d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add industry and size",
   "id": "cf59207a2dec0ebb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:42:31.782687Z",
     "start_time": "2024-11-07T09:41:34.282079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_load = ['name', 'industry', 'size'] # used due to memory error\n",
    "file_path_company_dataset = 'C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/free_company_dataset.csv'\n",
    "company_df = pd.read_csv(file_path_company_dataset, on_bad_lines='skip', usecols=columns_to_load) # bad line at 37k+\n",
    "company_df.rename(columns={\"name\": 'Entity_Name',}, inplace=True) #rename for readability"
   ],
   "id": "5aa5cae9d94f53b7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:47:13.816248Z",
     "start_time": "2024-11-07T09:45:35.871043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df.merge(company_df, on=\"Entity_Name\", how=\"left\", suffixes=('', '_drop'))\n",
    "df.to_csv(out_path + '/output.csv', sep=';', index=False)"
   ],
   "id": "30e8f46680de4b63",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:49:19.531008Z",
     "start_time": "2024-11-07T09:49:19.361113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_reduced = df[df[\"industry\"].notna()]\n",
    "df_reduced = df_reduced[df_reduced[\"Legal_Form\"] != 'N/A']\n",
    "df_reduced.to_csv(out_path + '/reduced_output.csv', sep=';', index=False)"
   ],
   "id": "c360e93936db27ad",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#1 Drop Suffixes ",
   "id": "591af6c3221202c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:49:28.856083Z",
     "start_time": "2024-11-07T09:49:24.938425Z"
    }
   },
   "cell_type": "code",
   "source": "forward_df = pd.read_excel(\"C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/forward_firm_universe.xlsx\")\n",
   "id": "c4be9d32a80fe1dc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:49:31.464163Z",
     "start_time": "2024-11-07T09:49:31.387528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract the last word from each entry in 'Entity_Name' as a potential suffix\n",
    "forward_df['Suffix'] = forward_df['Entity_Name'].apply(lambda x: x.split(\" \")[-1])\n",
    "\n",
    "suffix_list = forward_df['Suffix'].unique()\n",
    "\n",
    "with open(out_path+\"/suffixes.txt\", \"w\",  encoding=\"utf-8\") as file:\n",
    "    for item in suffix_list:\n",
    "        file.write(f\"{item}\\n\",)"
   ],
   "id": "b67d40c0b5353bba",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:50:23.111058Z",
     "start_time": "2024-11-07T09:50:22.927374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# List of suffixes to remove\n",
    "suffixes = [\n",
    "    \"PLC\", \"Co\", \"Corp\", \"Ltd\", \"LLC\", \"OOO\", \"PJSC\", \"SA\", \"SAE\", \"CJSC\", \"SAOG\", \n",
    "    \"SAOC\", \"SpA\", \"Bhd\", \"SAS\", \"Inc\", \"CV\", \"JSC\", \"Ltda\", \"Ltd.\", \"PAO\", \"AS\", \n",
    "    \"AŞ\", \"OAO\", \"AG\", \"LP\", \"LLP\", \"Co.,Ltd.\", \"Co.\", \"LTD\", \"BV\", \"PJS\", \"SAA\", \n",
    "    \"SPA\", \"AO\", \"S.A.\", \"ULC\", \"CVBA\", \"GmbH\", \"S.p.A.\", \"PCL\", \"Ltd.Shanxi\", \n",
    "    \"TOO\", \"B.V\", \"ShA\", \"AD\", \"PrAT\", \"PSC\", \"EAD\", \"Srl\", \"JV\", \"PT\", \"AB\", \n",
    "    \"S.A\", \"SARL\", \"Tbk\", \"S.L.\", \"Llc\", \"Limited\", \"LLC.\", \"PSA\", \"C.V.\", \n",
    "    \"P/S\", \"Ltd.LLC\", \"P.L.C.\", \"INC.\", \"KgaA\", \"NV\", \"Pvt\", \"OC\", \"SA/NV\", \n",
    "    \"JSC\", \"QSC\", \"QPSC\", \"LLC\", \"S.A.S.\", \"Cooperativa\", \"ASBL\", \"A/S\", \"SPV\", \n",
    "    \"Ltd(Sarl)\", \"AD(SA)\", \"Holdings\", \"D.O.O.\", \"KG\", \"ZRT\", \"A/S\", \"N.V.\", \n",
    "    \"CSJC\", \"LLC(Ltd)\", \"Sociedad\", \"SA(SP)\", \"GmbH & Co. KG\", \"AG & Co. KGaA\", \n",
    "    \"S.A.C.\", \"S.C.A.\", \"Cie\", \"GIE\", \"Co.,Ltd\", \"Spółka\", \"OOO\", \"KFT\", \"SNC\", \n",
    "    \"SAIC\", \"S.A.I.C.\", \"EEIG\", \"WLL\", \"Inc.\", \"Ltd/Ltd\", \"Sdn Bhd\", \"JLL\", \n",
    "    \"Plc\", \"Npo\", \"CO.LTD\", \"Ltda.\", \"I/S\", \"Inc..\", \"V.o.S.\", \"v.o.f.\", \"d.o.o.\", \n",
    "    \"株式会社\", \"KK\", \"Pty Ltd\", \"IAC\", \"S.A.P.I. de C.V.\", \"D.I.O.\", \"CBO\", \n",
    "    \"Comp.\", \"C.A\", \"B.V.\", \"Ltd.Pvt.\", \"Ltd LLC\", \"Ltd LLC.\", \"Pvt.Ltd.\", \n",
    "    \"S/A\", \"S.L\", \"A.E.I.E.\", \"GmbH\", \"OÜ\", \"S.R.L.\", \"W.L.L.\", \"Coop.\", \"B.V.I.\", \n",
    "    \"ltd.\", \"Ltd(Pty)\", \"有限会社\", \"주식회사\", \"DMCC\", \"CNSX\", \"Pty\", \"EIRL\", \"Comp.\", \n",
    "    \"S.A.R.L.\", \"ltd\", \"株式会社\", \"C.A.\", \"OÜ\", \"B.V.\", \"D.O.O.\", \"CJSC\", \"PJSC\", \n",
    "    \"Yhtiö\", \"株式会社\", \"Ltd\", \"株式会社\", \"EPE\", \"Csp\", \"GIE\", \"JLL\", \"Ltd(Company)\", \n",
    "    \"S.A.P.I.\", \"V.O.S.\", \"Società\", \"합자회사\", \"株式会社\", \"B.V.\", \"SARL\", \n",
    "    \"股份有限公司\", \"KT\", \"Pty.\", \"Co., Ltd.\", \"N.V.\", \"S.R.O.\", \"L.C.\", \"C.B.\", \"AB\", \n",
    "    \"L.L.C\", \"S.R.L.\", \"株式会社\", \"K.K.\", \"Pty Ltd\", \"L.P.\", \"AO\", \"P.C.\", \"A/S\", \n",
    "    \"I/K\", \"株式会社\", \"Ltd\", \"股份有限公司\", \"A/S\", \"株式会社\"\n",
    "]\n",
    "\n",
    "\n",
    "# Create a regex pattern that matches any suffix at the end of the string\n",
    "pattern = r'\\b(' + '|'.join(suffixes) + r')\\b\\.?$'\n",
    "print(f\"prev size:{len(forward_df)}\")\n",
    "# Remove suffixes from \"Entity_Name\" column\n",
    "forward_df['Entity_Name'] = forward_df['Entity_Name'].str.replace(pattern, '', regex=True).str.strip()\n",
    "forward_df.drop_duplicates(subset=['Entity_Name'], inplace=True)\n",
    "print(f\"after reduction size:{len(forward_df)}\")"
   ],
   "id": "ab6c28d1552a3e01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev size:23446\n",
      "after reduction size:23043\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:50:35.578850Z",
     "start_time": "2024-11-07T09:50:32.583154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Function to calculate cosine similarity between two strings\n",
    "def cosine_sim(text1, text2):\n",
    "    try:\n",
    "        vectorizer = TfidfVectorizer(stop_words=None).fit_transform([text1, text2])\n",
    "        cosine_similarities = cosine_similarity(vectorizer[0:1], vectorizer[1:2])\n",
    "        return cosine_similarities[0][0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Function to calculate Levenshtein distance between two strings\n",
    "def levenshtein_dist(text1, text2):\n",
    "    return Levenshtein.distance(text1, text2)\n",
    "\n",
    "\n",
    "# Function to calculate FuzzyWuzzy ratio between two strings\n",
    "def fuzzywuzzy_ratio(text1, text2):\n",
    "    return fuzz.ratio(text1, text2)\n",
    "\n",
    "\n",
    "# Function to merge similar names based on a selected method\n",
    "def merge_similar_names(df, name, method='cosine', cosine_threshold=0.8, lev_threshold=2, fuzzy_threshold=85):\n",
    "    # Define similarity functions based on the selected method\n",
    "    if method == 'cosine':\n",
    "        similarity_func = cosine_sim\n",
    "        threshold_func = lambda score: score >= cosine_threshold and score != 1\n",
    "    elif method == 'levenshtein':\n",
    "        similarity_func = levenshtein_dist\n",
    "        threshold_func = lambda score: score <= lev_threshold and score != 0\n",
    "    elif method == 'fuzzywuzzy':\n",
    "        similarity_func = fuzzywuzzy_ratio\n",
    "        threshold_func = lambda score: score >= fuzzy_threshold and score != 100\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method selected. Choose from 'cosine', 'levenshtein', or 'fuzzywuzzy'.\")\n",
    "\n",
    "    # Iterate over all company names\n",
    "    df['score'] = df['Entity_Name'].apply(similarity_func, args=(name,))\n",
    "    df['score'] = df['score'].apply(threshold_func)\n",
    "    return df"
   ],
   "id": "16d48532e089933d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Levenshtein",
   "id": "4c84e0648a2f273e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T10:04:50.550936Z",
     "start_time": "2024-11-07T10:02:53.452398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#methods = ['levenshtein', 'fuzzywuzzy', 'cosine']\n",
    "forward_df = pd.read_excel(\"C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/forward_firm_universe.xlsx\")\n",
    "\n",
    "forward_df['prefix'] = forward_df['Entity_Name'].apply(lambda x: x.split(\" \")[0])\n",
    "prefix_list = list(forward_df['prefix'].unique())\n",
    "forward_df['score'] = False\n",
    "selected_method = 'levenshtein'\n",
    "print(selected_method)\n",
    "print(f\"prev size:{len(forward_df)}\")\n",
    "start_time = time.time()\n",
    "for prefix in prefix_list:\n",
    "    #print(f\"{prefix_list.index(prefix) + 1}/{len(prefix_list)}\")\n",
    "    working_df = forward_df[forward_df['Entity_Name'].str.startswith(prefix)]\n",
    "    if len(working_df) < 2:\n",
    "        continue\n",
    "    # selected_method = 'cosine' # Change this to 'levenshtein' or 'fuzzywuzzy' to use other methods\n",
    "    merged_df = merge_similar_names(working_df.copy(), prefix, method=selected_method, cosine_threshold=0.7,\n",
    "                                    lev_threshold=2,\n",
    "                                    fuzzy_threshold=85)\n",
    "    forward_df.update(merged_df)\n",
    "\n",
    "forward_df = forward_df[~forward_df['score']]\n",
    "end_time = time.time()\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "print(f\"after reduction size:{len(forward_df)}\")\n"
   ],
   "id": "f5b94dc8000a04b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein\n",
      "prev size:23446\n",
      "Time taken: 115.815526 seconds\n",
      "after reduction size:23414\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "fuzzywuzzy",
   "id": "16fa2d302531c863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T12:31:54.416520Z",
     "start_time": "2024-11-07T12:29:50.144668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "forward_df = pd.read_excel(\"C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/forward_firm_universe.xlsx\")\n",
    "\n",
    "#methods = ['levenshtein', 'fuzzywuzzy', 'cosine']\n",
    "forward_df['prefix'] = forward_df['Entity_Name'].apply(lambda x: x.split(\" \")[0])\n",
    "prefix_list = list(forward_df['prefix'].unique())\n",
    "forward_df['score'] = False\n",
    "selected_method = 'fuzzywuzzy'\n",
    "print(selected_method)\n",
    "print(f\"prev size:{len(forward_df)}\")\n",
    "start_time = time.time()\n",
    "for prefix in prefix_list:\n",
    "    #print(f\"{prefix_list.index(prefix) + 1}/{len(prefix_list)}\")\n",
    "    working_df = forward_df[forward_df['Entity_Name'].str.startswith(prefix)]\n",
    "    if len(working_df) < 2:\n",
    "        continue\n",
    "    # selected_method = 'cosine' # Change this to 'levenshtein' or 'fuzzywuzzy' to use other methods\n",
    "    merged_df = merge_similar_names(working_df.copy(), prefix, method=selected_method, cosine_threshold=0.7,\n",
    "                                    lev_threshold=2,\n",
    "                                    fuzzy_threshold=85)\n",
    "    forward_df.update(merged_df)\n",
    "\n",
    "forward_df = forward_df[~forward_df['score']]\n",
    "end_time = time.time()\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "print(f\"after reduction size:{len(forward_df)}\")\n"
   ],
   "id": "260abe4bcfee91f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzzywuzzy\n",
      "prev size:23446\n",
      "Time taken: 116.896533 seconds\n",
      "after reduction size:23420\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "cosine",
   "id": "b7565c200819ce6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T12:35:34.271904Z",
     "start_time": "2024-11-07T12:32:12.073705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "forward_df = pd.read_excel(\"C:/Users/max00/Documents/Problem_Set_Forward Analytics/Problem_Set_Forward_Analytics/data/forward_firm_universe.xlsx\")\n",
    "\n",
    "#methods = ['levenshtein', 'fuzzywuzzy', 'cosine']\n",
    "forward_df['prefix'] = forward_df['Entity_Name'].apply(lambda x: x.split(\" \")[0])\n",
    "prefix_list = list(forward_df['prefix'].unique())\n",
    "forward_df['score'] = False\n",
    "selected_method = 'cosine'\n",
    "print(selected_method)\n",
    "print(f\"prev size:{len(forward_df)}\")\n",
    "start_time = time.time()\n",
    "for prefix in prefix_list:\n",
    "    #print(f\"{prefix_list.index(prefix) + 1}/{len(prefix_list)}\")\n",
    "    working_df = forward_df[forward_df['Entity_Name'].str.startswith(prefix)]\n",
    "    if len(working_df) < 2:\n",
    "        continue\n",
    "    # selected_method = 'cosine' # Change this to 'levenshtein' or 'fuzzywuzzy' to use other methods\n",
    "    merged_df = merge_similar_names(working_df.copy(), prefix, method=selected_method, cosine_threshold=0.7,\n",
    "                                    lev_threshold=2,\n",
    "                                    fuzzy_threshold=85)\n",
    "    forward_df.update(merged_df)\n",
    "\n",
    "forward_df = forward_df[~forward_df['score']]\n",
    "end_time = time.time()\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "print(f\"after reduction size:{len(forward_df)}\")\n"
   ],
   "id": "b83a9c634459b89c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine\n",
      "prev size:23446\n",
      "empty vocabulary; perhaps the documents only contain stop words\n",
      "Time taken: 200.539974 seconds\n",
      "after reduction size:23425\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9461ace9d2082555"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
